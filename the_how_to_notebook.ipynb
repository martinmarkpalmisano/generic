{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Excel files or csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# specify the path of the file\n",
    "file_name = \"x590_12months_cluster_final_features.xlsx\"\n",
    "file_name1 = \"scatt_nulls.csv\"\n",
    "# specify the sheet name (as string) or index (0-based)\n",
    "df1 = pd.read_excel(file_name, sheet_name=\"x590_12months_cluster_final_fea\")   # by sheet name\n",
    "df2 = pd.read_excel(file_name, sheet_name=\"Unique Clusters\")   # by sheet name\n",
    "df3 = pd.read_csv(file_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique elements in a column\n",
    "\n",
    "df1_max['V Vin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f5a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the max value of a metric for an element in the id column \n",
    "\n",
    "max_dcir_per_vin = max_dcir_data3.groupby(\"V_VIN\")[\"INTERNAL_RESISTANCE_DIAGNOSTIC\"].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times each VIN appears in the dataset\n",
    "\n",
    "count_df = uc5_scatt_mp.groupby(['V_VIN']).size().reset_index(name='count')\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c34250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows where a colum has nulls\n",
    "uc5_scatt_data = uc5_scatt_mp.dropna(subset=['MAX_WARRANTY_RATIO'])\n",
    "\n",
    "# drop all rows where INTERNAL_RESISTANCE_DIAGNOSTIC is null\n",
    "max_dcir_data = output_metr_summ.dropna(subset=['INTERNAL_RESISTANCE_DIAGNOSTIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52de6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selezionare righe la cui colonna ha il valore preciso\n",
    "uc5_scatt_data = uc5_scatt_data[uc5_scatt_data['PART_REPLACED'] != 'TRUE']\n",
    "\n",
    "# get all data for a specific VIN\n",
    "vin_data = uc5_mp[uc5_mp['V_VIN'] == 'SADHA2B11L1F81404']\n",
    "\n",
    "# get all data for a specific date\n",
    "last_diag_metr_summ = diag_metr_summ[diag_metr_summ['SNAPSHOT_DATE'] == '2025-08-21 00:00:00+00:00']\n",
    "\n",
    "# for each VIN gets its last entire row\n",
    "last_values = data.loc[data.groupby(\"V_VIN\")[\"SNAPSHOT_DATE\"].idxmax()]\n",
    "\n",
    "# how to select distinct VINs with their warranty ratios using drop_duplicates\n",
    "distinct_vins = uc5_mp[['V_VIN', 'WARRANTY_TIME_RATIO', 'WARRANTY_DISTANCE_RATIO']].drop_duplicates()\n",
    "\n",
    "# create a new column with the MAX WARRANTY RATIO\n",
    "distinct_vins['MAX_WARRANTY_RATIO'] = distinct_vins[['WARRANTY_TIME_RATIO', 'WARRANTY_DISTANCE_RATIO']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks all items in the column of a dataframe are contained in another one\n",
    "\n",
    "def compare_column_values(df1: pd.DataFrame, df2: pd.DataFrame, col1: str, col2: str):\n",
    "   \"\"\"\n",
    "   Compare unique values from one DataFrame column against another.\n",
    "   Parameters:\n",
    "       df1 (pd.DataFrame): First DataFrame.\n",
    "       df2 (pd.DataFrame): Second DataFrame.\n",
    "       col1 (str): Column name in df1 to check.\n",
    "       col2 (str): Column name in df2 to compare against.\n",
    "   Returns:\n",
    "       Tuple[bool, List]:\n",
    "           - True if all unique elements in df1[col1] are in df2[col2], else False.\n",
    "           - List of missing elements (empty if all elements are found).\n",
    "   \"\"\"\n",
    "   # Ensure columns exist\n",
    "   if col1 not in df1.columns:\n",
    "       raise ValueError(f\"Column '{col1}' not found in first DataFrame.\")\n",
    "   if col2 not in df2.columns:\n",
    "       raise ValueError(f\"Column '{col2}' not found in second DataFrame.\")\n",
    "   # Get unique elements from both columns\n",
    "   unique_values_df1 = set(df1[col1].dropna().unique())\n",
    "   values_df2 = set(df2[col2].dropna().unique())\n",
    "   # Identify which values from df1 are not in df2\n",
    "   missing_values = sorted(unique_values_df1 - values_df2)\n",
    "   all_found = len(missing_values) == 0\n",
    "   return all_found, missing_values\n",
    "\n",
    "# Compare\n",
    "result, missing = compare_column_values(uc5_scatt_mp, parts_data, 'V_VIN', 'V_VIN')\n",
    "print(\"All values found?\", result)\n",
    "print(\"Missing values:\", len(missing))\n",
    "print(\"Missing values:\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8476a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find replicates in a column and how many times\n",
    "\n",
    "def find_duplicates_with_counts(df, column_name):\n",
    "   \"\"\"\n",
    "   Returns a DataFrame with duplicate values in a specified column\n",
    "   and the number of times each value appears.\n",
    "   Parameters:\n",
    "   df (pd.DataFrame): The input DataFrame.\n",
    "   column_name (str): Name of the column to check for duplicates.\n",
    "   Returns:\n",
    "   pd.DataFrame: DataFrame with columns:\n",
    "       - value: the duplicate value\n",
    "       - count: how many times it appears\n",
    "   \"\"\"\n",
    "   # Count occurrences\n",
    "   counts = df[column_name].value_counts()\n",
    "   # Filter only values that appear more than once\n",
    "   duplicates = counts[counts > 1].reset_index()\n",
    "   duplicates.columns = [column_name, 'count']\n",
    "   return duplicates\n",
    "\n",
    "duplicates_count = find_duplicates_with_counts(df1_max, 'V Vin')\n",
    "duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the latest readings for a measure with the indexing method\n",
    "\n",
    "# Step 1: Get the index of the latest date per id\n",
    "latest_indices = uc5_data.groupby('V_VIN')['PROCESSABLE_DATE'].idxmax()\n",
    "# Step 2: Extract the rows with those indices\n",
    "latest_read_distr_data = uc5_data.loc[latest_indices].reset_index(drop=True)\n",
    "\n",
    "plt.hist(min_distr_data['SOH'], bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Minimum Measure per ID')\n",
    "plt.xlabel('Minimum Measure')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot a hist with labels\n",
    "\n",
    "# Choose number of bins\n",
    "num_bins = 19\n",
    "# Create bins and labels\n",
    "min_distr_data['bin'], bins = pd.cut(min_distr_data['SOH'], bins=num_bins, retbins=True, include_lowest=True)\n",
    "\n",
    "bin_counts = min_distr_data['bin'].value_counts().sort_index()\n",
    "\n",
    "# Basic histogram with labeled counts\n",
    "plt.hist(min_distr_data['SOH'], bins=bins, edgecolor='black')\n",
    "for i in range(len(bin_counts)):\n",
    "   bin_center = (bins[i] + bins[i+1]) / 2\n",
    "   plt.text(bin_center, bin_counts.iloc[i], str(bin_counts.iloc[i]),\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "plt.title('Distribution of Minimum Measure per ID')\n",
    "plt.xlabel('Minimum Measure')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "bin_size = 0.01\n",
    "min_val = min_distr_data['SOH'].min()\n",
    "max_val = min_distr_data['SOH'].max()\n",
    "# Create bin edges based on bin size\n",
    "bins = np.arange(min_val, max_val + bin_size, bin_size)\n",
    "\n",
    "# Assign bin labels\n",
    "min_distr_data['bin'] = pd.cut(min_distr_data['SOH'], bins=bins, include_lowest=True)\n",
    "# Count how many items fall into each bin\n",
    "bin_counts = min_distr_data['bin'].value_counts().sort_index()\n",
    "# Map count back to each row\n",
    "min_distr_data['bin_count'] = min_distr_data['bin'].map(bin_counts)\n",
    "\n",
    "plt.hist(min_distr_data['SOH'], bins=bins, edgecolor='black')\n",
    "# Add count labels to each bin\n",
    "for i in range(len(bin_counts)):\n",
    "   bin_center = (bins[i] + bins[i+1]) / 2\n",
    "   count = bin_counts.iloc[i]\n",
    "   plt.text(bin_center, count, str(count), ha='center', va='bottom', fontsize=9)\n",
    "plt.title('Distribution of Minimum Measure per ID')\n",
    "plt.xlabel('Minimum Measure')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of items in a column\n",
    "# Category Distribution: Bar Chart\n",
    "category_counts = df['Category'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values, palette=\"Blues_d\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Total Orders by Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac66207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "corr_matrix = df_reset[['Sales', 'Profit', 'Quantity', 'Discount', 'Ship Days']].corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    cmap='RdYlBu',\n",
    "    fmt=\".3f\",\n",
    "    linewidths=1,\n",
    "    cbar=True,\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"Correlation Heatmap of Key Metrics\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f04437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bar chart\n",
    "\n",
    "top_regions = df.groupby('Region')['Sales'].sum().sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=top_regions.values, y=top_regions.index, palette='crest')\n",
    "plt.title('Total Sales by Region')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff84f5",
   "metadata": {},
   "source": [
    "add from those Kaggle examples"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
